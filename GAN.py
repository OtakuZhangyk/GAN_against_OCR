import os
import numpy as np
from PIL import Image
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, UpSampling2D, Concatenate, LeakyReLU, BatchNormalization, Conv2DTranspose, Dense, Reshape, Add
from tensorflow.keras.models import Model
from tensorflow.keras import Input
import pytesseract
import pandas as pd
from io import StringIO, BytesIO
import time
from skimage.metrics import structural_similarity as compare_ssim
import textdistance
import cv2
import datetime
from math import sqrt

# get list of filenames of train images
def load_data(data_dir = 'img64_1024_1'):
    # Define data directory and file extension
    file_ext = '.png'

    # Load image data from directory
    data = []
    for file in os.listdir(data_dir):
        if file.endswith(file_ext):
            img = Image.open(os.path.join(data_dir, file))
            data.append(np.array(img))
    
    data = np.array(data)
    # expand a channel dimension to images, from (num of images,50,1080) to (num of images,50,1080,1)
    data = np.expand_dims(data, axis=3)
    return data

# apply noise array generated by generator to image
def apply_noise(image, noise):
    # Normalize image to range [-2, 0]
    normalized_image = (image / 127.5) - 2

    noise = noise - 1

    # Add noise to the normalized image
    noisy_image = normalized_image + noise

    # Clip values to range [-2, 0]
    noisy_image = np.clip(noisy_image, -2, 0)

    # Convert the noisy image back to the range [0, 255]
    noisy_image = ((noisy_image + 2) * 127.5).astype(np.uint8)

    return noisy_image

# Call Tesseract OCR to analyze image and return confidence and result in 2D np array
def OCR_(img_data):
    start_time = time.time()
    # add config tsv to return tsv format string including result and confidence
    tsv_string = pytesseract.image_to_data(img_data, config = 'tsv')
    end_time = time.time()
    # transform into file stream
    tsv_file = StringIO(tsv_string)
    # load using pandas
    try:
        df = pd.read_csv(tsv_file, sep='\t', quoting = 3)
    except Exception as e:
        print(e)
        print(tsv_string)
        exit()

    # get data with conf != -1 and get their conf and text
    filtered_data = df[df['conf'] != -1][['conf', 'text']]

    filtered_data = filtered_data[filtered_data['text'] != ' ']

    # Convert the filtered data to a NumPy array
    result_np_array = filtered_data.to_numpy()

    # [conf text]
    return result_np_array, end_time - start_time

# Levenshtein Distance (Edit Distance), normalized to 0~1, 1 for same
def str_similarity(string1, string2):
    distance = textdistance.levenshtein.distance(string1, string2)
    max_length = max(len(string1), len(string2))
    similarity = 1 - (distance / max_length)
    return similarity**3


# get ssim of real and fake image
def img_sim(image1, image2 = None, algo = 'Non0'):
    if algo == 'ssim':
        return compare_ssim(image1, image2, multichannel=True)
    elif algo == 'mse':
        return 127.5**2-np.mean((image1.astype("float") - image2.astype("float")) ** 2)
    elif algo == 'ssim+mse':
        return compare_ssim(image1, image2, multichannel=True) + 127.5**2 - np.mean((image1.astype("float") - image2.astype("float")) ** 2)
    elif algo == 'noise_mean':
        return 1 - abs(np.mean((image1 / 127.5) - 1))
    elif algo == 'L2':
        img = (image1 / 127.5) - 1
        img = img.flatten()
        dist = abs(np.linalg.norm(img))
        return sqrt(dist) - 1.2
    elif algo == 'Non0':
        img = (image1 / 127.5) - 1
        img = img.flatten()
        count = np.count_nonzero(np.abs(img) > 0.02)
        prop = count / len(img)
        return prop

# evaluate the performance of the generator on each pair of real and fake image
def evaluate(real_np, real_time, fake_np, fake_time, img_sim):
    # Define the weights for each factor
    w_str_sim = 1.0
    w_confidence = 0
    #w_time = 0.0
    w_img_sim = 0.08

    real_str_np = real_np[:,1]
    fake_str_np = fake_np[:,1]
    real_conf_np = real_np[:,0]
    fake_conf_np = fake_np[:,0]

    # string similiarity(accuracy)
    real_str = ' '.join(str(i) if i != '|' else 'I' for i in real_str_np)
    fake_str = ' '.join(str(i) if i != '|' else 'I' for i in fake_str_np)
    str_sim = str_similarity(real_str, fake_str)

    # # confidence drop(negative confidence if wrong), nromalized
    # if str_sim == 1.0:
    #     if fake_str_np.shape[0] == 0:
    #         conf_drop = 0
    #     else:
    #         conf_drop = np.mean(real_conf_np) - np.mean(fake_conf_np)

    # else:
    #     for i in range(min(real_str_np.shape[0], fake_str_np.shape[0])):
    #         if real_str_np[i] != fake_str_np[i]:
    #             fake_conf_np[i] = -fake_conf_np[i]
    #     if fake_str_np.shape[0] == 0:
    #         conf_drop = 0
    #     else:
    #         conf_drop = np.mean(real_conf_np) - np.mean(fake_conf_np)
    # conf_drop /= 100.0
    # #print(conf_drop)
    # if conf_drop < 0:
    #     conf_drop = 0
    # elif conf_drop > 1:
    #     conf_drop = 1

    # time increase, normalized
    #time_incre = (fake_time - real_time) / fake_time

    # evaluation equation
    #eval_ = w_str_sim * str_sim + w_confidence * conf_drop + w_time * time_incre + w_img_sim * img_sim
    #print(str_sim, conf_drop, img_sim)
    eval_ = w_str_sim * str_sim + w_img_sim * img_sim
    #print(str_sim, img_sim)

    #eval_ /= w_str_sim + w_img_sim

    return eval_, str_sim

# transform np array to PIL image object
def numpy_to_pil_image(np_array):
    # Convert the array values to the range [0, 255]
    #np_array = (np_array * 127.5 + 127.5).astype(np.uint8)

    # Remove the channel dimension if it's 1
    if np_array.shape[2] == 1:
        np_array = np_array.reshape(np_array.shape[0], np_array.shape[1])

    # Create a PIL.Image object from the NumPy array
    pil_image = Image.fromarray(np_array)
    img = pil_image.convert("L")

    buffer = BytesIO()
    img.save(buffer, format='PNG')
    buffer.seek(0)
    
    return Image.open(buffer)

def standard_gen_loss(y_true, y_pred):
    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(y_true, y_pred)

# take input image and generate a noisy image
def build_generator(img_shape):
    # Define the encoder part
    def encoder_layer(input_layer, filters, kernel_size=3, strides=1, activation=LeakyReLU(alpha=0.2), batch_norm=True):
        layer = Conv2D(filters, kernel_size, strides=strides, padding='same')(input_layer)
        layer = activation(layer)
        if batch_norm:
            layer = BatchNormalization(momentum=0.8)(layer)
        return layer

    # Define the decoder part
    def decoder_layer(input_layer, skip_layer, filters, kernel_size=3, strides=1, activation=LeakyReLU(alpha=0.2), batch_norm=True):
        layer = UpSampling2D()(input_layer)
        layer = Conv2D(filters, kernel_size, strides=strides, padding='same')(layer)
        layer = activation(layer)
        if batch_norm:
            layer = BatchNormalization(momentum=0.8)(layer)
        layer = Concatenate()([layer, skip_layer])
        return layer

    input_img = Input(shape=img_shape)
    #input_noise = Input(shape=(latent_dim,))

    # Encoder
    e1 = encoder_layer(input_img, 64, strides=2)
    e2 = encoder_layer(e1, 128, strides=2)
    e3 = encoder_layer(e2, 256, strides=2)
    e4 = encoder_layer(e3, 512, strides=2)

    # # Add the noise input
    # noise_layer = Dense(np.prod(e4.get_shape().as_list()[1:]), input_dim=latent_dim)(input_noise)
    # noise_layer = Reshape((e4.get_shape().as_list()[1], e4.get_shape().as_list()[2], e4.get_shape().as_list()[3]))(noise_layer)
    # e4 = Add()([e4, noise_layer])

    # Decoder
    d1 = decoder_layer(e4, e3, 256)
    d2 = decoder_layer(d1, e2, 128)
    d3 = decoder_layer(d2, e1, 64)
    output_noise = Conv2DTranspose(img_shape[2], kernel_size=3, strides=2, padding='same', activation='tanh')(d3)
    return Model(inputs=input_img, outputs=output_noise)
    # d4 = decoder_layer(d3, input_img, 32)

    # output_noise = Conv2D(1, kernel_size=3, strides=1, padding='same', activation='tanh')(d4)
    # noisy_img = tf.keras.layers.Add()([output_noise, input_img])
    # noisy_img = tf.keras.layers.Activation('sigmoid')(noisy_img)

    # generator = Model(inputs=input_img, outputs=noisy_img)
    # return generator


# Define the training loop
def train(epochs, batch_size, latent_dim):
    # get the current date and time
    now = datetime.datetime.now()

    # format the date and time into a string
    date_string = now.strftime("%m-%d-%H-%M-%S")

    path = os.path.join('./tmp', date_string)
    os.mkdir(path)

    X_train = load_data()
    # real_np, real_time = OCR_(numpy_to_pil_image(X_train[0]))
    # print(real_np)
    # print(real_time)
    # return

    generator = build_generator((64, 1024, 1))


    learning_rate = 0.0002
    beta_1 = 0.5

    # Define the optimizer
    generator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate, beta_1, clipvalue=1.0), loss='binary_crossentropy')

    # Training loop
    for epoch in range(epochs):
        # Select a random batch of real images
        idx = np.random.randint(0, X_train.shape[0], batch_size)
        real_images = X_train[idx]

        # Generate a batch of noise_arrays
        #noise = np.random.normal(0, 1, (batch_size, latent_dim))
        output_noise = generator.predict(real_images)
        #fake_images = (fake_images * 127.5 + 127.5).astype(np.uint8)
        # print(np.max(output_noise), np.min(output_noise))
        # return

        best_str_sim = 2.0
        best_fake_image = None

        batch_eval_list = []
        # Evaluate real and fake images using unknown_func
        for i in range(real_images.shape[0]):
            fake_image = apply_noise(real_images[i], output_noise[i])

            real_np, real_time = OCR_(numpy_to_pil_image(real_images[i]))
            fake_np, fake_time = OCR_(numpy_to_pil_image(fake_image))
            sim = img_sim(np.abs(fake_image - real_images[i]))
            eval_, str_sim = evaluate(real_np, real_time, fake_np, fake_time, sim)
            batch_eval_list.append(eval_)
            if best_str_sim > str_sim:
                best_str_sim = str_sim
                best_fake_image = fake_image



        batch_eval_np = np.array(batch_eval_list)
        #real_labels = np.ones(batch_size)
        real_labels = np.zeros(batch_size)
        #print(batch_eval_np)

        generator_loss = generator.train_on_batch(real_images, batch_eval_np)

        # # Calculate loss and gradients for the generator
        # with tf.GradientTape() as gen_tape:
        #     gen_loss = standard_gen_loss(real_labels, batch_eval_np)
            
        #     # Calculate gradients
        #     gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)

        # # Update the generator's weights
        # optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))

        
        # Print progress
        print("Epoch: %d, Generator Loss: %f" % (epoch, generator_loss))
        print(f'\tBest str sim: {best_str_sim}')


        if epoch % 5 == 0:
            cv2.imwrite(f'./tmp/{date_string}/Epoch{epoch}_ss{best_str_sim}.png', best_fake_image)
            print(f'\tSaved image ./tmp/{date_string}/Epoch{epoch}_ss{best_str_sim}.png')
        #return

def main():
    # Set the training parameters and train the GAN
    latent_dim = 100
    epochs = 1000
    batch_size = 32
    train(epochs, batch_size, latent_dim)

if __name__ == "__main__":
    main()